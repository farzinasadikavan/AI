{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "    '''\n",
    "    This class is used in order to implement custom feed-forward neural networks.\n",
    "    The FeedForwardNN class stores a list of layers that determines all network layers.\n",
    "    It also consists of the learning rate and loss function.\n",
    "    '''\n",
    "    def __init__(self, input_shape):\n",
    "        '''\n",
    "        Parameters:\n",
    "            input_shape: the size of the first input to our neural network.\n",
    "        '''\n",
    "        \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
    "        '''\n",
    "         This method adds a new custom layer to the layers_list.\n",
    "         Parameters:\n",
    "             n_neurons: number of neurons in this layer\n",
    "             activation: the activation function of this layer, default is Relu\n",
    "             initial_weight: either a uniform or normal, default is uniform\n",
    "             initializing_parameters: other initializing parameters such as low, high, mean, var, etc\n",
    "        '''\n",
    "         \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        '''\n",
    "        This method is used to set training parameters.\n",
    "        Parameters:\n",
    "            loss: loss function, default is CrossEntropy\n",
    "            lr: learning rate, default is 1e-3\n",
    "        '''\n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "    \n",
    "    \n",
    "    def forward(self, network_input):\n",
    "        '''\n",
    "        This method calculates the output of the complete neural network for a passed input.\n",
    "        Parameters:\n",
    "            network_input: input of the neural network\n",
    "        Returns:\n",
    "            network_output: output of the neural network after forwarding the network_input\n",
    "        '''\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        # TODO: Implement\n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        '''\n",
    "        This method trains the neural network using specified parameters.\n",
    "        It runs the __train private method epoch times and fills the log dictionary.\n",
    "        Parameters:\n",
    "            epochs: number of epochs to run\n",
    "            trainloader: DataLoader for train data\n",
    "            testloader: DataLoader for test data\n",
    "            print_results: whether or not to print the results\n",
    "        Returns:\n",
    "            log: complete log of the training process as a dictionary consisting of\n",
    "            train_accuracy, train_loss, test_accuracy, test_loss\n",
    "        '''\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "    \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "        '''\n",
    "        Trains the neural network for one epoch.\n",
    "        Parameters:\n",
    "            trainloader: A DataLoader consisting of train data\n",
    "        Returns:\n",
    "            batch_accuracy, batch_loss: mean of all batch_accuracies, batch_losses\n",
    "        '''\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "        '''\n",
    "        Test the neural network using a testloader.\n",
    "        Parameters:\n",
    "            testloader: A DataLoader of test data\n",
    "        Returns:\n",
    "            batch_accuracy, batch_loss: mean of all batch_accuracies, batch_losses\n",
    "        '''\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        '''\n",
    "        Trains the neural network for one batch of train data.\n",
    "        Parameters:\n",
    "            x_batch: one batch data\n",
    "            y_batch: labels for one batch\n",
    "        Returns:\n",
    "            (batch_accuracy, batch_average_loss)\n",
    "        '''\n",
    "        # TODO: Implement\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "        \n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        '''\n",
    "        Tests the neural network for one batch of test data.\n",
    "        Parameters:\n",
    "            x_batch: one batch data\n",
    "            y_batch: labels for one batch\n",
    "        Returns:\n",
    "            (batch_accuracy, batch_average_loss)\n",
    "        '''  \n",
    "        # TODO: Implement\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "            \n",
    "        \n",
    "    def __get_labels(self, outputs):\n",
    "        '''\n",
    "        Parameters:\n",
    "            outputs: output of the neural network\n",
    "        Returns:\n",
    "            labels: labels generated from the outputs of the neural network\n",
    "        '''\n",
    "        # TODO: Implement\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        '''\n",
    "        Computes accuracy by comparing output and expected_output.\n",
    "        Parameters:\n",
    "            output: actual output of the neural network\n",
    "            expected_output: expected output\n",
    "        Returns:\n",
    "            accuracy\n",
    "        '''\n",
    "        # TODO: Implement\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "        '''\n",
    "        Updates weights of all layers according to neural network output and labels.\n",
    "        Parameters:\n",
    "            output: output of the neural network\n",
    "            y_train: y labels for one batch of train data\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        # TODO: Implement\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample code for building and training a model\n",
    "\n",
    "INPUT_SHAPE = ...\n",
    "LEARNING_RATE = ...\n",
    "EPOCHS = ...\n",
    "TRAINLOADER = ...\n",
    "TESTLOADER = ...\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(..., input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(..., activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
